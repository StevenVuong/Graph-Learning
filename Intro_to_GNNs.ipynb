{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro to GNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Youtube Link: https://www.youtube.com/watch?v=8owQBFAHw7E&ab_channel=TensorFlow"
      ],
      "metadata": {
        "id": "GGRR_pDERmKH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiIU3jMxI2ED"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install tensorflow\n",
        "!pip install spektral\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import spektral"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = spektral.datasets.citation.Citation(name='cora', dtype='float32')"
      ],
      "metadata": {
        "id": "us721tKnI96r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj = dataset[0]['a']\n",
        "node_features = dataset[0]['x']\n",
        "edge_features = dataset[0]['e']\n",
        "labels = dataset[0]['y']\n",
        "\n",
        "train_mask = dataset.mask_tr\n",
        "test_mask = dataset.mask_te\n",
        "val_mask = dataset.mask_va"
      ],
      "metadata": {
        "id": "2fdhwCYZJN6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj = adj + np.eye(adj.shape[0]) # add identity matrix (self connection)\n",
        "\n",
        "adj = adj.astype('float32')\n",
        "node_featuers = node_features.astype('float32')\n",
        "\n",
        "print(adj.shape)\n",
        "print(node_features.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "print(np.sum(train_mask))\n",
        "print(np.sum(val_mask))\n",
        "print(np.sum(test_mask))"
      ],
      "metadata": {
        "id": "hI1ONw8CKnxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_softmax_cross_entropy(logits, labels, mask):\n",
        "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n",
        "    mask = tf.cast(mask, dtype=tf.float32) # mask loss\n",
        "    mask /= tf.reduce_mean(mask) # average the value so can take product with loss\n",
        "    loss *= mask\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "def masked_accuracy(logits, labels, mask):\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "    accuracy_all = tf.cast(correct_prediction, tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    mask /= tf.reduce_mean(mask)\n",
        "    accuracy_all *= mask\n",
        "    return tf.reduce_mean(accuracy_all) # accuracy over nodes we care about"
      ],
      "metadata": {
        "id": "dTmWK1JOMZfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gnn(fts, adj, transform, activation):\n",
        "    seq_fts = transform(fts) # point wise transformation, W\n",
        "    ret_fts = tf.matmul(adj, seq_fts) # matrix mult of adjancecy and W\n",
        "    return activation(ret_fts) # apply activation function"
      ],
      "metadata": {
        "id": "6SeIQFyCNeUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cora(fts, adj, gnn_fn, units, epochs, lr):\n",
        "    lyr_1 = tf.keras.layers.Dense(units)\n",
        "    lyr_2 = tf.keras.layers.Dense(7) # for number of classes; classification\n",
        "\n",
        "    def cora_gnn(fts, adj):\n",
        "        hidden = gnn_fn(fts, adj, lyr_1, tf.nn.relu) # first pass with transform\n",
        "        logits = gnn_fn(hidden, adj, lyr_2, tf.identity) # identity to not transform\n",
        "        return logits # return this as nn predictions\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "    best_accuracy = 0.0\n",
        "    for ep in range(epochs + 1):\n",
        "        with tf.GradientTape() as t: # to record gradients\n",
        "            logits = cora_gnn(fts, adj) # compute predictions\n",
        "            loss = masked_softmax_cross_entropy(logits, labels, train_mask) # calc loss of training mask\n",
        "        \n",
        "        variables = t.watched_variables() # get variables gradient tape was watching (specify variables to update)\n",
        "        grads = t.gradient(loss, variables) \n",
        "        optimizer.apply_gradients(zip(grads, variables)) # apply gradients via optimizer\n",
        "\n",
        "        logits = cora_gnn(fts, adj) # take logits of fts and adj\n",
        "        val_accuracy = masked_accuracy(logits, labels, val_mask)\n",
        "        test_accuracy = masked_accuracy(logits, labels, test_mask)\n",
        "\n",
        "        if val_accuracy > best_accuracy: \n",
        "            best_accuracy = val_accuracy\n",
        "            # should save best model; but we just print \n",
        "            print('Epoch', ep, '| Training Loss:', loss.numpy(), '| Val Accuracy:', val_accuracy.numpy(), '| Test Accuracy:', test_accuracy.numpy())"
      ],
      "metadata": {
        "id": "60HzIqcDN_mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cora(node_features, adj, gnn, 32, 200, 0.01) # 32 units, 200 epochs, lr 0.01 (standard params)\n",
        "# pass raw adj to this, multiply by 0,1 matrix; sum pooling. Expecting to have issues with scaling, not best result possible\n",
        "# very quickly converges to a set of weights"
      ],
      "metadata": {
        "id": "AF7W8ylvPuyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cora(node_features, tf.eye(adj.shape[0]), gnn, 32, 200, 0.01) # way to test; adj to identity\n",
        "# point wise MLP may not go beyond MLP"
      ],
      "metadata": {
        "id": "_phj7BenQByH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deg = tf.reduce_sum(adj, axis=-1) # try mean pooling; compute degree of each node spread across diagonal\n",
        "train_cora(node_features, adj/deg, gnn, 32, 200, 0.01) # normalised grad; help deal with exploding/vanishing gradient"
      ],
      "metadata": {
        "id": "vIoVRxSVQtTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_deg = tf.linalg.diag(1.0 / tf.sqrt(deg)) \n",
        "norm_adj = tf.matmul(norm_deg, tf.matmul(adj, norm_deg)) # proposed by thomas kipf\n",
        "train_cora(node_features, norm_adj, gnn, 32, 200, 0.01)"
      ],
      "metadata": {
        "id": "m2B9Oa_iRAEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "02g_pw3wRUTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}