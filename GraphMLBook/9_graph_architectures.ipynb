{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Driven Graph-Powered Application\n",
    "\n",
    "**Lambda architectures** provides a framework to structure scalable applications that require large-scale processing and real-time updates. Apply the framework in the context of graph powered applications. Describe **graph processing engines** and **graph querying engines**, so we cover in chapter 9:\n",
    "- Overview of lambda architectures\n",
    "- Lambda architectures for graph-powered applications\n",
    "- Technologies and examples of graph processing engines\n",
    "- Graph querying engines and graph databases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install neo4j==4.2.0\n",
    "!pip install gremlinpython==3.4.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Architectures\n",
    "Focus of scalable architectures that can handle large amounts of data and can provide alerts in real time, using the latest available information. These systems must scale to large number of users or data by increasing resources horizontally or vertically. Lambda architecture is designed to process massive quantities of data and ensure large throughput efficiently, preserving reduced latency and ensuring fault tolerance and negligible errors. We have three different layers:\n",
    "- **batch layer**: Sits on top of the storage system, and can handle all historical data, as well as perform **online analytical processing (OLAP)** computation on the entire dataset. New data is continuously ingested and stored. Large-scale processing typically achieved via massively parallel jobs, aiming to produce aggregation, structuring and computation of relevant information. In terms of ML, model training that relies on historic information is generally done at this layer, producing a trained model to be used in either batch prediction or real-time execution.\n",
    "- **speed layer**: Low-latency layer allows real-time processing of information to provide timely updates and information. Generally fed by a streaming process, usually involving fast computation that does not require a long computational time or load. Produces output integrated with data generated by batch layer in (near) real time, providing support for **OLTP** operations. May also use some outputs of OLTP computations, such as trained model. Often ML models that serve predictions are embedded in speed layers.\n",
    "- **serving layer**: Duty to organise, structure and index information for fast data retrieval from batch and speed layer. Thus integrates outputs of batch layer with most updated and real-time information of speed-layer to deliver user a unified and coherent view of the data. Serving layer can be composed of a persistence layer that integrates both historic aggregation and real-time updates. Information generally exposed to user via direct connection to DB or accessible with specific domain query language, such as SQL or via dedicated RESTful API servers.\n",
    "\n",
    "Some of the main pros with Lambda architecture:\n",
    "-  **No server management**: Abstracts functional layers so no installing, maintaining or administering any software/infrastructure\n",
    "-  **Flexible Scaling**: Can be automatic to scale horizontally or vertically\n",
    "-  **Automated high availability**: Represents serverless design which already has built-in availability and fault tolerance\n",
    "-  **Business agility**: Reacts in real time to changing business/market scenarios\n",
    "\n",
    "Limitations:\n",
    "- Separate two interconnected processing flows: **batch layer** and **speed layer**, requiring developers to build and maintain separate code bases for batch and stream processes, requiring more complexity and overhead code management.\n",
    "\n",
    "## Lambda architectures for Graph-Powered Applications\n",
    "- **Graph processing engine**: Executes computations on graph structure to extract features, compute statistics, compute metrics and **Key Performance indicators (KPIs)** and identify relevant subgraphs that require OLAP.\n",
    "- **Graph querying engine**: Allows us to persist network data and provides fast information retrieval and efficient querying and graph traversal (usually via graph querying languages). Information is already persisted in some data storage and no further computation is required, other than some final aggregation so indexing is crucial for high performance and low latency.\n",
    "\n",
    "Graph processing engines sit on top of batch layers and produce outputs that may be stored and indexed in appropriate graph databases. These databases are the backend of graph querying engines which allow information to be easily and quickly retrieved, representing the operational views used by the serving layer. Can make sense to run processing and querying engine on top of the same infrastructure. \n",
    "\n",
    "Graph proccessing engines require information on the whole graph to be accessed quickly, ie. having it in memory and may not require distributed architectures depending on context. Though data can grow so much it is not viable to use a single machine; which case there are solutions: \n",
    "-  **Apache Spark GraphX**: Distributed representation of graph using Resilient Distributed Datasets (RDDs) for both edges and vertices, so edges are assigned to different machines and vertices can span multiple machines.\n",
    "-  **Apache Graph**: Iterative graph processing system built for high scalability. Currently used by Facebook to analyse social graph formed by users, their connections is built upon Hadoop to utilise the potential of structured datasets at large scale.\n",
    "\n",
    "The choice of algorithms is smaller in shared machines because:\n",
    "1. Algorithms in a distributed way is more complex than in a shared machine due to communication among nodes, which reduces efficiency\n",
    "2. Only algorithms that (nearly) scale linearly with num. data points should be implemented to ensure horizontal scalability, by increasing computational nodes as dataset increases\n",
    "\n",
    "There is an equivalent of map-reduce for graphs, **Pregel**, consisting of a sequence of iterations, each called a **superstep** involving a node and its neighbours. \n",
    "\n",
    "Examples of **graph databases** to store non-structured data:\n",
    "- Neo4j\n",
    "    - Can distribute to large datasets via sharding, distributing over multiple nodes\n",
    "    - Also flexible and user-friendly, good for MVP/PoC to get started in agile manner\n",
    "    - Has Graph Data Science library\n",
    "    - Can query via Gremlin\n",
    "    - Though scaling based on sharding and breaking down large graphs into smaller subgraphs may not be the best option\n",
    "- JanusGraph\n",
    "    - Scalable graph for storing and querying graphs distributed across multi-machine cluster with hundreds of billions of vertices and edges\n",
    "    - Sits on top of GCloud Bigtable, Apache HBase, Apache Cassandra, ScyllaDB. Abstracting graph view on top of them.\n",
    "    - Can efficiently handle **supernodes** with extremely large degree which are often bottlenecks\n",
    "    - Graph can be analysed with Gremlin with Java connectors and Python bindings\n",
    "- OrientDB\n",
    "- Amazon Neptune \n",
    "- etc..\n",
    "\n",
    "And have **graph query languages** that allow us to traverse the underlying graphs. Gremlin is a functional language whereby operators are grouped together to form path-like expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
